import requests
import yaml
from models.markov._train_markov_model import load_model, generate_text



# Load config file
with open("config.yaml", "r") as f:
    config = yaml.safe_load(f)



def tiny_llama_model(text: str) -> str:
    """
    
    """
    system_prompt = config["system_prompt"] # not yet implementes
    full_prompt = f"Human: {text} Assistant:"

    # Hit the API endpoint.
    response = requests.post(url=config["api_url"],
                            json={"prompt": full_prompt},
                            headers={"Content-Type": "application/json"})

    # Check the server's response.
    if response.ok:
        print("LLM Reply: ", response.json()["reply"])

        return response.json()["reply"]

    else:
        print("Error:", response.status_code, response.text)

        return "Model offline!"


def random_markov_model(length : int,
                        start_word : str,
                        model_path : str) -> str:
    """
    Uses a random markov model trained off some poetry.
    NOTE: model output is not conditioned off user input.

    Parameters
    ----------
    length : int
        How many words should be in the output.
    start_word : str
        The first word in the response.
        NOTE: this word must belong to the vocabulary.
    model_path : str
        Path to the trained model.
    
    Returns
    -------
    str
        Words in a string.
    """
    # Load model
    loaded_model = load_model(model_path)

    # Generate and print text
    text = generate_text(loaded_model,
                        start_word=start_word,
                        length=length)

    return text


def get_response(text : str,
                 model : str) -> str:
    """
    Produces a text reply to a text input.

    Parameters
    ----------
    text : str
        The input text that the response is conditioned on.
    model : str
        Which model to use. Current models:
            - "echo"
                Repeats back the input text.
            - "random_markov"
                Random text from a trained markov model.
            - "tiny_llama"
                A small LLM

    Returns
    ------
    str
        The reply generated by the model.
    """
    if model == "echo":
        return text

    if model == "random_markov":
        response = random_markov_model(length=30,
                                   start_word="the",
                                   model_path="models/markov/_random_poems_model.pkl")

        return response

    if model == "tiny_llama":
        response = tiny_llama_model(text=text)

        return response
